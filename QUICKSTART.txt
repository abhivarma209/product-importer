========================================
QUICKSTART GUIDE
========================================

Get the Acme Product Importer up and running in 5 minutes!

========================================
STEP 1: PREREQUISITES
========================================

Make sure you have these installed:

âœ“ Python 3.11 or higher
  Download: https://www.python.org/downloads/

âœ“ Node.js 18 or higher
  Download: https://nodejs.org/

âœ“ PostgreSQL 13 or higher
  Download: https://www.postgresql.org/download/
  Must be running on localhost:5432

âœ“ Redis 6 or higher
  Download: https://redis.io/download
  Must be running on localhost:6379

Verify installations:
  python --version    # Should be 3.11+
  node --version      # Should be 18+
  psql --version      # Should be 13+
  redis-cli ping      # Should return PONG

========================================
STEP 2: SETUP DATABASE
========================================

Open PostgreSQL CLI:
  psql -U postgres

Create database:
  CREATE DATABASE fileimporter;
  \q

Verify:
  psql -U postgres -d fileimporter

If successful, you're ready to continue!

========================================
STEP 3: SETUP BACKEND
========================================

Navigate to backend:
  cd acme-service

Create virtual environment (recommended):
  python -m venv venv
  
  # Windows:
  venv\Scripts\activate
  
  # Mac/Linux:
  source venv/bin/activate

Install dependencies:
  pip install -r requirements.txt

Create .env file:
  Create a file named ".env" in acme-service/ folder

Add these lines to .env:
  postgres_db=fileimporter
  postgres_host=localhost
  postgres_port=5432
  postgres_user=postgres
  postgres_password=YOUR_POSTGRES_PASSWORD
  
  redis_url=redis://localhost:6379/0
  celery_broker_url=redis://localhost:6379/0
  celery_result_backend=redis://localhost:6379/0
  
  environment=development

Replace YOUR_POSTGRES_PASSWORD with your actual password!

========================================
STEP 4: RUN BACKEND
========================================

You need TWO terminals for the backend:

TERMINAL 1 - API Server:
  cd acme-service
  python run.py

You should see:
  INFO:     Uvicorn running on http://127.0.0.1:8000
  INFO:     Application startup complete.

Test it:
  Open browser: http://localhost:8000
  You should see: {"message": "Acme Product Importer API", ...}

TERMINAL 2 - Celery Worker:
  cd acme-service
  celery -A dependencies.celery_app:celery_app worker --loglevel=info

You should see:
  [tasks]
    . app.tasks.process_csv_upload
    . app.tasks.trigger_webhooks_async
  
  celery@YOUR_COMPUTER ready.

Keep BOTH terminals running!

========================================
STEP 5: SETUP FRONTEND
========================================

Open a NEW terminal (Terminal 3):

Navigate to frontend:
  cd acme-client

Install dependencies:
  npm install

This will take a few minutes...

Create .env.local file:
  Create a file named ".env.local" in acme-client/ folder

Add this line:
  NEXT_PUBLIC_API_URL=http://localhost:8000

========================================
STEP 6: RUN FRONTEND
========================================

In the same terminal (still in acme-client/):

Start development server:
  npm run dev

You should see:
  â–² Next.js 14.x.x
  - Local:        http://localhost:3000
  - Ready in Xs

Open browser:
  http://localhost:3000

You should see the Acme Product Importer interface!

========================================
STEP 7: TEST THE APPLICATION
========================================

Generate test data:
  Open Terminal 4
  cd acme-service
  python SAMPLE_CSV_GENERATOR.py

This creates:
  âœ“ sample_products_1k.csv (1,000 products)
  âœ“ sample_products_10k.csv (10,000 products)
  âœ“ products_with_duplicates.csv (test deduplication)

Upload a CSV:
  1. Go to http://localhost:3000
  2. Click "Upload" tab
  3. Click "Choose File"
  4. Select sample_products_1k.csv
  5. Click "Upload"
  6. Watch the progress bar!

View products:
  1. Click "Products" tab
  2. You should see 1,000 products
  3. Try search, filter, pagination
  4. Click "ðŸ“Š Export to Excel" to download

Test webhooks:
  1. Click "Webhooks" tab
  2. Click "+ Add Webhook"
  3. URL: https://webhook.site (get a test URL)
  4. Event Type: product.created
  5. Click "Save"
  6. Create a product to trigger webhook

========================================
RUNNING SUMMARY
========================================

You need FOUR terminals:

Terminal 1 (Backend API):
  cd acme-service
  python run.py

Terminal 2 (Celery Worker):
  cd acme-service
  celery -A dependencies.celery_app:celery_app worker --loglevel=info

Terminal 3 (Frontend):
  cd acme-client
  npm run dev

Terminal 4 (Optional - Testing):
  cd acme-service
  python SAMPLE_CSV_GENERATOR.py

Access Points:
  Frontend:  http://localhost:3000
  Backend:   http://localhost:8000
  API Docs:  http://localhost:8000/docs

========================================
COMMON ISSUES & SOLUTIONS
========================================

Issue: "Connection refused" when starting backend
Solution:
  âœ“ Check PostgreSQL is running
  âœ“ Check Redis is running
  âœ“ Verify credentials in .env file
  âœ“ Make sure database "fileimporter" exists

Issue: "Module not found" errors
Solution:
  âœ“ Activate virtual environment (venv)
  âœ“ Run: pip install -r requirements.txt

Issue: Frontend can't connect to backend
Solution:
  âœ“ Check backend is running on port 8000
  âœ“ Check .env.local has correct API URL
  âœ“ Try http://localhost:8000 in browser

Issue: CSV upload not processing
Solution:
  âœ“ Make sure Celery worker is running (Terminal 2)
  âœ“ Check Celery worker logs for errors
  âœ“ Verify Redis is running: redis-cli ping

Issue: "Port already in use"
Solution:
  âœ“ Backend (8000): Kill process using port 8000
  âœ“ Frontend (3000): Kill process using port 3000
  
  Windows:
    netstat -ano | findstr :8000
    taskkill /PID <PID> /F
  
  Mac/Linux:
    lsof -ti:8000 | xargs kill -9

Issue: Excel export not working
Solution:
  âœ“ Make sure openpyxl is installed
  âœ“ Check: pip list | grep openpyxl
  âœ“ If missing: pip install openpyxl

========================================
STOPPING THE APPLICATION
========================================

To stop all services:

1. Frontend (Terminal 3):
   Press Ctrl+C

2. Celery Worker (Terminal 2):
   Press Ctrl+C

3. Backend API (Terminal 1):
   Press Ctrl+C

To stop database services:
  PostgreSQL:
    Windows: Stop service via Services
    Mac: brew services stop postgresql
    Linux: sudo systemctl stop postgresql
  
  Redis:
    Windows: Stop service via Services
    Mac: brew services stop redis
    Linux: sudo systemctl stop redis

========================================
NEXT STEPS
========================================

Now that you're running:

1. Explore API Documentation:
   http://localhost:8000/docs
   Try out all the endpoints interactively!

2. Test Features:
   âœ“ Create products manually
   âœ“ Upload large CSV files (try 10k records)
   âœ“ Export to Excel
   âœ“ Configure webhooks
   âœ“ Search and filter products

3. Read Documentation:
   âœ“ README.txt - Main documentation
   âœ“ PROJECT_STRUCTURE.txt - Project structure
   âœ“ acme-service/README.txt - Backend details
   âœ“ acme-service/STRUCTURE.txt - Code structure
   âœ“ acme-client/README.txt - Frontend details

4. Customize:
   âœ“ Modify CSV columns (update models.py & schemas.py)
   âœ“ Add new API endpoints (create new route file)
   âœ“ Customize UI (edit components)
   âœ“ Add authentication (implement auth middleware)

========================================
USEFUL COMMANDS
========================================

Backend:
  Start API:           python run.py
  Start Celery:        celery -A dependencies.celery_app:celery_app worker --loglevel=info
  Generate test CSV:   python SAMPLE_CSV_GENERATOR.py
  Install packages:    pip install -r requirements.txt
  Check packages:      pip list

Frontend:
  Start dev server:    npm run dev
  Build for prod:      npm run build
  Start prod server:   npm run start
  Install packages:    npm install
  Check packages:      npm list

Database:
  Connect to DB:       psql -U postgres -d fileimporter
  List tables:         \dt
  View products:       SELECT * FROM products LIMIT 10;
  Count products:      SELECT COUNT(*) FROM products;
  Drop all tables:     DROP TABLE products, webhooks, upload_tasks CASCADE;

Redis:
  Check connection:    redis-cli ping
  Monitor commands:    redis-cli monitor
  Flush all data:      redis-cli FLUSHALL

========================================
DEVELOPMENT WORKFLOW
========================================

Daily development routine:

1. Start services:
   Terminal 1: cd acme-service && python run.py
   Terminal 2: cd acme-service && celery -A dependencies.celery_app:celery_app worker --loglevel=info
   Terminal 3: cd acme-client && npm run dev

2. Make changes:
   - Backend: Edit files in acme-service/
   - Frontend: Edit files in acme-client/
   - Both support hot reload!

3. Test changes:
   - Backend: Check http://localhost:8000/docs
   - Frontend: Check http://localhost:3000
   - End-to-end: Upload CSV and verify

4. Stop services:
   - Press Ctrl+C in each terminal

========================================
API TESTING
========================================

Using Swagger UI (Recommended):
  1. Go to http://localhost:8000/docs
  2. Click "Try it out" on any endpoint
  3. Fill in parameters
  4. Click "Execute"
  5. View response

Using cURL:
  # List products
  curl http://localhost:8000/api/products

  # Create product
  curl -X POST http://localhost:8000/api/products \
    -H "Content-Type: application/json" \
    -d '{"sku":"TEST001","name":"Test Product","price":19.99}'

  # Get product
  curl http://localhost:8000/api/products/1

  # Health check
  curl http://localhost:8000/api/health

Using Postman:
  1. Import OpenAPI spec from http://localhost:8000/openapi.json
  2. Test all endpoints
  3. Save requests for future use

========================================
PRODUCTION DEPLOYMENT
========================================

When ready to deploy:

1. Backend (Railway, Render, AWS):
   - Update .env with production values
   - Set environment=production
   - Use managed PostgreSQL and Redis
   - Run Celery worker as background service
   - Use gunicorn: gunicorn main:app -w 4 -k uvicorn.workers.UvicornWorker

2. Frontend (Vercel, Netlify):
   - Update .env.local with production API URL
   - Run: npm run build
   - Deploy dist folder
   - Configure domain

3. Database:
   - Use managed PostgreSQL (Railway, AWS RDS)
   - Enable backups
   - Set up monitoring

4. Monitoring:
   - Add logging service (Sentry, LogRocket)
   - Set up uptime monitoring
   - Configure alerts

========================================
GETTING HELP
========================================

Resources:
  âœ“ README.txt - Main documentation
  âœ“ PROJECT_STRUCTURE.txt - Detailed structure
  âœ“ acme-service/README.txt - Backend guide
  âœ“ acme-service/STRUCTURE.txt - Code organization
  âœ“ API Docs - http://localhost:8000/docs

Check Logs:
  âœ“ Backend API: Terminal 1 output
  âœ“ Celery Worker: Terminal 2 output
  âœ“ Frontend: Terminal 3 output
  âœ“ Browser Console: F12 in browser

Common Log Files:
  âœ“ PostgreSQL: varies by OS
  âœ“ Redis: varies by OS
  âœ“ Application: terminal output

========================================
SUCCESS CHECKLIST
========================================

You're ready when you can:

âœ“ Start backend API (Terminal 1)
âœ“ Start Celery worker (Terminal 2)
âœ“ Start frontend (Terminal 3)
âœ“ Access http://localhost:3000
âœ“ See API docs at http://localhost:8000/docs
âœ“ Generate test CSV
âœ“ Upload CSV file
âœ“ View products in UI
âœ“ Export products to Excel
âœ“ Create/edit/delete products
âœ“ Configure webhooks

If all above work, you're good to go! ðŸŽ‰

========================================
TIPS & BEST PRACTICES
========================================

âœ“ Use virtual environment for Python
âœ“ Keep terminals organized (label them)
âœ“ Check logs when something fails
âœ“ Test with small CSV first (1k records)
âœ“ Use API docs for testing endpoints
âœ“ Enable hot reload for development
âœ“ Keep dependencies updated
âœ“ Read error messages carefully
âœ“ Use .gitignore (never commit .env files!)
âœ“ Backup database before major changes

========================================

Happy coding! ðŸš€

For detailed documentation, see README.txt

========================================
